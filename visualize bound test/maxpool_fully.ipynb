{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as f\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3598, -0.8551, -1.3404, -0.8318, -0.5547]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0379, -0.7123]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = torch.randint(1,10,[1,1,3]).float()\n",
    "x = torch.randn(1,1,5)\n",
    "#X = torch.tensor([[[-2.7,3.2]]])\n",
    "epsilon = 0.01\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(5,8),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(8),\n",
    "    nn.Linear(1,2),\n",
    ")\n",
    "\n",
    "print(x)\n",
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(x, 'maxpool_x_.pt') \n",
    "# torch.save(model.state_dict(),'maxpool_model_fully.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_d(zl,zu,z = None):\n",
    "    \n",
    "    check = torch.is_tensor(z)\n",
    "    if check:\n",
    "        z = z.squeeze(0)\n",
    "        #print('z:',z)\n",
    "    \n",
    "    d = (zl >= 0).detach().type_as(zl) # d check each point in I+ set\n",
    "    I = ((zu > 0).detach() * (zl < 0).detach())  # I check each point in I set\n",
    "    \n",
    "    d_u = torch.zeros(*(zl.size()))\n",
    "    \n",
    "    d_b = (zl >= 0).detach().type_as(zl)\n",
    "    d_b*= zu\n",
    "    \n",
    "    d_l = (zl >= 0).detach().type_as(zl)\n",
    "    \n",
    "    d_l*= zl.detach().type_as(zl)\n",
    "    \n",
    "#     print('check_z:',check_z)\n",
    "#     print('I:',I)\n",
    "#     print('z:',z)\n",
    "    \n",
    "    I_z = (I.type_as(zl))*zl.detach().type_as(zl) # 問 1.z是否>=0  問 2. 是否neuro在set I 3. 乘上 z\n",
    "    \n",
    "    if I.sum().item() > 0:\n",
    "            d[I] += zu[I]/(zu[I] - zl[I])\n",
    "            \n",
    "            d_u[I] += zu[I]/(zu[I] - zl[I])          \n",
    "                \n",
    "            d_b[I] += ( -(zu[I]*zl[I])/(zu[I] - zl[I]) )\n",
    "            \n",
    "            d_l[I] += I_z[I]\n",
    "\n",
    "    return d , d_u, d_b , d_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_middle_u_l_(D_u, D_b, D_L, z, zu):\n",
    "    \n",
    "    z = z.squeeze(0)\n",
    "    \n",
    "    u_ = D_u*zu + D_b\n",
    "    l_ = D_L\n",
    "    \n",
    "    return u_, l_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ZM(zR):\n",
    "    \n",
    "    zM = [0.0]\n",
    "    length = zR.size(2)\n",
    "    #print(length)\n",
    "    \n",
    "    for idx in range(1,length):\n",
    "        m = nn.MaxPool1d(idx+1)\n",
    "        zM.append(m(zR[:,:,:idx]))\n",
    "    \n",
    "    zM = torch.tensor(zM)\n",
    "    \n",
    "    return zM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bar_u_l(uR, lR, zM, zR):\n",
    "    \n",
    "    zR, zM = zR.flatten(), zM.flatten()\n",
    "    bar_z = (zR - zM)\n",
    "    #print('zR:',zR)\n",
    "    #print('zM:',zM)\n",
    "    print('bar_z:',bar_z)\n",
    "    \n",
    "    uR, lR = uR.flatten(), lR.flatten()\n",
    "    print('uR:',uR)\n",
    "    print('lR:',lR)\n",
    "    \n",
    "    lM = [0]\n",
    "    uM = [0]\n",
    "    u_bar = []\n",
    "    l_bar = []\n",
    "    \n",
    "    #u_bar.append(uR[0] - lM[0])\n",
    "    #print('u_bar[0]:',u_bar[0])\n",
    "    \n",
    "    \n",
    "    for i in range(0,len(bar_z)):\n",
    "        \n",
    "        # get u_bar, l_bar\n",
    "        #print('i,uR[i],lM[i]',i,uR[i],lM[i])\n",
    "        u_bar.append(uR[i] - lM[i])\n",
    "        l_bar.append(lR[i] - uM[i])\n",
    "        \n",
    "        # get u_ , l_\n",
    "        if u_bar[i] < 0:\n",
    "            l_ , u_ = 0 , 0\n",
    "        \n",
    "        elif l_bar[i] >= 0:\n",
    "            l_, u_ = l_bar[i], u_bar[i]\n",
    "            \n",
    "        elif l_bar[i] < 0 and u_bar[i] > 0 :\n",
    "            \n",
    "            # get l_\n",
    "            l_ = 0\n",
    "                \n",
    "            # get u_\n",
    "            u_ = (u_bar[i]/(u_bar[i]-l_bar[i])) * u_bar[i] - ((u_bar[i]*l_bar[i])/(u_bar[i]-l_bar[i]))\n",
    "            \n",
    "        # get uM, lM\n",
    "        lM.append(lM[i] + l_)\n",
    "        uM.append(uM[i] + u_)\n",
    "    \n",
    "#     print('u_bar:',torch.tensor(u_bar))\n",
    "#     print('l_bar:',torch.tensor(l_bar))\n",
    "    print('uM:',torch.tensor(uM))\n",
    "    print('lM:',torch.tensor(lM))\n",
    "    print('last u_, l_:',u_, l_)\n",
    "    \n",
    "    u_bar = torch.tensor(u_bar).unsqueeze(0)\n",
    "    l_bar = torch.tensor(l_bar).unsqueeze(0)\n",
    "    \n",
    "    return u_bar, l_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_ReLU_bound(x, Net, D, upper_bds, lower_bds):\n",
    "    \n",
    "    #print(Net)\n",
    "    n = torch.numel(D)\n",
    "    c = -torch.eye(n)\n",
    "    nu = []\n",
    "    nu_b = []\n",
    "    nu_x = [x.squeeze(0)]\n",
    "    l1 = []\n",
    "    \n",
    "    upper_l_nu = []\n",
    "    lower_l_nu = []\n",
    "    \n",
    "    pos_Upper = len(upper_bds) - 1\n",
    "    pos_Lower = len(lower_bds) - 1\n",
    "    \n",
    "    for idx, layer in enumerate(reversed(Net)):\n",
    "        if isinstance(layer, nn.ReLU):\n",
    "            #print(c)\n",
    "            nu.append(-D.t()*c)\n",
    "            \n",
    "            I = ((upper_bds[pos_Upper] > 0) * (lower_bds[pos_Lower] < 0)).t().float()\n",
    "            #print(\"I:\",I)\n",
    "            \n",
    "            upper_l_nu.append( (lower_bds[pos_Lower].t()*(I*nu[-1]).clamp(min = 0)).sum(0) )\n",
    "            lower_l_nu.append(  (lower_bds[pos_Lower].t()*(-1*I*nu[-1]).clamp(min = 0)).sum(0) )\n",
    "            \n",
    "            #print(upper_l_nu[-1])\n",
    "            #print(lower_l_nu[-1])\n",
    "            \n",
    "        if isinstance(layer, nn.Linear):\n",
    "            W = layer.weight\n",
    "            b = layer.bias.unsqueeze(0)\n",
    "            \n",
    "            nu_b.append(torch.mm(b,nu[-1]))\n",
    "            nu.append(torch.mm(W.t(),nu[-1]))\n",
    "            \n",
    "            #print(\"nu_hat_1:\",nu[-1])\n",
    "            #print(\"nu_b_term:\",nu_b[-1])\n",
    "    \n",
    "    nu_x.append(torch.mm(nu_x[-1],nu[-1])) # compute x^T hat(nu_1)\n",
    "    l1.append(nu[-1].abs().sum(0))\n",
    "    \n",
    "    upper = sum(nu_b) + nu_x[-1] + epsilon*l1[-1] - sum(upper_l_nu)\n",
    "    lower = sum(nu_b) + nu_x[-1] - epsilon*l1[-1] + sum(lower_l_nu)\n",
    "            \n",
    "    return upper, lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Kappa(Rho, bar_upper_bds, bar_lower_bds):\n",
    "    \n",
    "    bar_upper = bar_upper_bds[-1][0]\n",
    "    bar_lower = bar_lower_bds[-1][0]\n",
    "    Rho = Rho.squeeze(0)\n",
    "    \n",
    "    #print('bar_upper:',bar_upper)\n",
    "    #print('bar_lower:',bar_lower)\n",
    "    #print('bar_lowr size:',bar_lower.size(0))\n",
    "    m = bar_lower.size(0)\n",
    "    n = Rho.size(0)\n",
    "    #print('m,n:',m,n)\n",
    "    \n",
    "    kappa = torch.zeros(n)\n",
    "    \n",
    "    for u,l in zip(reversed(bar_upper), reversed(bar_lower)):\n",
    " \n",
    "        u_, l_ = u.data, l.data\n",
    "        \n",
    "        k = torch.zeros(n)\n",
    "        if u_ < 0 :\n",
    "            k = 0*Rho\n",
    "        \n",
    "        elif l_ >= 0 :\n",
    "            k = 1*Rho\n",
    "        \n",
    "        elif l_ < 0  and u_ > 0 :\n",
    "            k = (u_/(u_- l_))*Rho\n",
    "        \n",
    "        print('u,l,Rho,k:',u_, l_ ,Rho,k )\n",
    "        \n",
    "        kappa = torch.cat((kappa, k), 0)\n",
    "        \n",
    "        Rho-= k\n",
    "    \n",
    "    #print('kappa.size :',kappa)\n",
    "    kappa = kappa.view(m+1,n).t()[:,1:]\n",
    "    kappa = kappa.flip(1)\n",
    "    #print('kappa:',kappa)\n",
    "    \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upper_lower(x, epsilon, Net, D = None, upper_bds = None, lower_bds = None, bar_upper_bds = None, bar_lower_bds = None):\n",
    "    \n",
    "    nu_b = []\n",
    "    nu = []\n",
    "    nu_x = [x.squeeze(0)]   #### note : x input is 3-dim\n",
    "    l1 = []\n",
    "    Big_Kappa = []\n",
    "    \n",
    "    upper_max_term = []\n",
    "    lower_max_term = []\n",
    "    \n",
    "    upper_relu_term = []\n",
    "    lower_relu_term = []\n",
    "    \n",
    "    n = Net[-1].out_features\n",
    "    nu.append(torch.eye(n))\n",
    "    \n",
    "    if D != None :\n",
    "        pos_Upper = len(upper_bds) - 1\n",
    "        pos_Lower = len(lower_bds) - 1\n",
    "        pos_bar_U = len(bar_upper_bds) - 1\n",
    "        pos_bar_L = len(bar_lower_bds) - 1\n",
    "        pos_d = len(D) - 1\n",
    "    \n",
    "    print('In Net')\n",
    "    for idx,layer in enumerate(reversed(Net)):\n",
    "        print('\\n')\n",
    "        print(idx,layer)\n",
    "        \n",
    "        if isinstance(layer, nn.Linear):\n",
    "            W = layer.weight\n",
    "            b = layer.bias.unsqueeze(0)\n",
    "            \n",
    "            nu_b.append(torch.mm(b,nu[-1]))\n",
    "            nu.append(torch.mm(W.t(),nu[-1]))\n",
    "            \n",
    "            #print('nu_b:',nu_b[-1])\n",
    "            #print('nu:',nu[-1])\n",
    "            \n",
    "        if isinstance(layer, nn.MaxPool1d):\n",
    "            Beta = nu[-1]\n",
    "            print('Beta:', Beta)\n",
    "            Rho = Beta\n",
    "            kappa = get_Kappa(Rho, bar_upper_bds, bar_lower_bds).t()\n",
    "            print('kappa:',kappa)\n",
    "            Big_Kappa.append(kappa)\n",
    "            \n",
    "            bar_I = ((bar_upper_bds[pos_bar_U] > 0) * (bar_lower_bds[pos_bar_L] < 0)).float().t()\n",
    "            print('bar_I:',bar_I)\n",
    "            #print('(bar_I*kappa):',(bar_I*kappa))\n",
    "            print('bar_lower_bds[pos_bar_L]:',bar_lower_bds[pos_bar_L].t())\n",
    "            \n",
    "            upper_max_term.append( (bar_lower_bds[pos_bar_L].t()*(bar_I*kappa).clamp(min = 0)).sum(0) )\n",
    "            lower_max_term.append(  (bar_lower_bds[pos_bar_L].t()*(-1*bar_I*kappa).clamp(min = 0)).sum(0) )\n",
    "            \n",
    "            print('upper_max_term:',upper_max_term[-1])\n",
    "            print('lower_max_term:',lower_max_term[-1])\n",
    "            \n",
    "        if isinstance(layer, nn.ReLU):\n",
    "            kappa = Big_Kappa[-1]\n",
    "            print('kappa:',kappa)\n",
    "            \n",
    "            d = D[pos_d].t()\n",
    "            print('d:',d)\n",
    "            \n",
    "            nu.append(kappa*d)\n",
    "            print('nu:',nu[-1])\n",
    "            \n",
    "            # test for only relu\n",
    "#             d = D[pos_d].t()\n",
    "#             nu.append(d*nu[-1])\n",
    "            \n",
    "            I = ((upper_bds[pos_Upper] > 0) * (lower_bds[pos_Lower] < 0)).t().float()\n",
    "            print('I:',I)\n",
    "            \n",
    "            upper_relu_term.append( (lower_bds[pos_Lower].t()*(I*nu[-1]).clamp(min = 0)).sum(0) )\n",
    "            lower_relu_term.append(  (lower_bds[pos_Lower].t()*(-1*I*nu[-1]).clamp(min = 0)).sum(0) )\n",
    "            \n",
    "            print('upper_relu_term:',upper_relu_term[-1])\n",
    "            print('lower_relu_term:',lower_relu_term[-1])\n",
    "            \n",
    "        if idx == 3 : break\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    print('nu_x:',nu_x[-1])\n",
    "    nu_x.append(torch.mm(nu_x[-1],nu[-1])) # compute x^T hat(nu_1)\n",
    "    l1.append(nu[-1].abs().sum(0))\n",
    "    \n",
    "    if D == None :\n",
    "        upper = sum(nu_b) + nu_x[-1] + epsilon*l1[-1]\n",
    "        lower = sum(nu_b) + nu_x[-1] - epsilon*l1[-1]\n",
    "\n",
    "    else:\n",
    "        upper = sum(nu_b) + nu_x[-1] + epsilon*l1[-1] - sum(upper_relu_term) - sum(upper_max_term)\n",
    "        lower = sum(nu_b) + nu_x[-1] - epsilon*l1[-1] + sum(lower_relu_term) + sum(lower_max_term)\n",
    "        print('upper:',upper)\n",
    "        print('lower:',lower)\n",
    "        \n",
    "    nu_x.clear()\n",
    "    nu.clear()\n",
    "    nu_b.clear()\n",
    "    upper_relu_term.clear()\n",
    "    lower_relu_term.clear()\n",
    "    upper_max_term.clear()\n",
    "    lower_max_term.clear()\n",
    "    \n",
    "    \n",
    "    return upper,lower\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 Linear(in_features=5, out_features=8, bias=True)\n",
      "In Net\n",
      "\n",
      "\n",
      "0 Linear(in_features=5, out_features=8, bias=True)\n",
      "\n",
      "\n",
      "nu_x: tensor([[ 0.3598, -0.8551, -1.3404, -0.8318, -0.5547]])\n",
      "u: tensor([[-0.2624,  0.5090, -0.5194, -0.5244,  0.4379, -0.2870, -0.3821,  0.1776]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "l: tensor([[-0.2748,  0.4877, -0.5455, -0.5427,  0.4168, -0.3111, -0.4019,  0.1540]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "1 ReLU()\n",
      "z: tensor([[[-0.2686,  0.4983, -0.5325, -0.5335,  0.4273, -0.2990, -0.3920,\n",
      "           0.1658]]], grad_fn=<AddBackward0>)\n",
      "triangle\n",
      "u_: tensor([[-0.0000, 0.5090, -0.0000, -0.0000, 0.4379, -0.0000, -0.0000, 0.1776]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "l_: tensor([[-0.0000, 0.4877, -0.0000, -0.0000, 0.4168, -0.0000, -0.0000, 0.1540]])\n",
      "optimization\n",
      "u__: tensor([[0.0000, 0.5090, 0.0000, 0.0000, 0.4379, 0.0000, 0.0000, 0.1776]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "l__: tensor([[0.0000, 0.4877, 0.0000, 0.0000, 0.4168, 0.0000, 0.0000, 0.1540]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "2 MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "zR: tensor([[[0.0000, 0.4983, 0.0000, 0.0000, 0.4273, 0.0000, 0.0000, 0.1658]]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "zM: tensor([0.0000, 0.0000, 0.4983, 0.4983, 0.4983, 0.4983, 0.4983, 0.4983])\n",
      "bar_z: tensor([ 0.0000,  0.4983, -0.4983, -0.4983, -0.0710, -0.4983, -0.4983, -0.3325],\n",
      "       grad_fn=<SubBackward0>)\n",
      "uR: tensor([-0.0000, 0.5090, -0.0000, -0.0000, 0.4379, -0.0000, -0.0000, 0.1776],\n",
      "       grad_fn=<AsStridedBackward>)\n",
      "lR: tensor([-0.0000, 0.4877, -0.0000, -0.0000, 0.4168, -0.0000, -0.0000, 0.1540])\n",
      "uM: tensor([0.0000, 0.0000, 0.5090, 0.5090, 0.5090, 0.5090, 0.5090, 0.5090, 0.5090])\n",
      "lM: tensor([0.0000, 0.0000, 0.4877, 0.4877, 0.4877, 0.4877, 0.4877, 0.4877, 0.4877])\n",
      "last u_, l_: 0 0\n",
      "bar_u: tensor([[-0.0000,  0.5090, -0.4877, -0.4877, -0.0497, -0.4877, -0.4877, -0.3101]])\n",
      "bar_l: tensor([[-0.0000,  0.4877, -0.5090, -0.5090, -0.0922, -0.5090, -0.5090, -0.3550]])\n",
      "\n",
      "\n",
      "3 Linear(in_features=1, out_features=2, bias=True)\n",
      "In Net\n",
      "\n",
      "\n",
      "0 Linear(in_features=1, out_features=2, bias=True)\n",
      "\n",
      "\n",
      "1 MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "Beta: tensor([[ 1.0000, -0.6154]], grad_fn=<MmBackward>)\n",
      "u,l,Rho,k: tensor(-0.3101) tensor(-0.3550) tensor([ 1.0000, -0.6154], grad_fn=<SqueezeBackward1>) tensor([0., -0.], grad_fn=<MulBackward0>)\n",
      "u,l,Rho,k: tensor(-0.4877) tensor(-0.5090) tensor([ 1.0000, -0.6154], grad_fn=<AsStridedBackward>) tensor([0., -0.], grad_fn=<MulBackward0>)\n",
      "u,l,Rho,k: tensor(-0.4877) tensor(-0.5090) tensor([ 1.0000, -0.6154], grad_fn=<AsStridedBackward>) tensor([0., -0.], grad_fn=<MulBackward0>)\n",
      "u,l,Rho,k: tensor(-0.0497) tensor(-0.0922) tensor([ 1.0000, -0.6154], grad_fn=<AsStridedBackward>) tensor([0., -0.], grad_fn=<MulBackward0>)\n",
      "u,l,Rho,k: tensor(-0.4877) tensor(-0.5090) tensor([ 1.0000, -0.6154], grad_fn=<AsStridedBackward>) tensor([0., -0.], grad_fn=<MulBackward0>)\n",
      "u,l,Rho,k: tensor(-0.4877) tensor(-0.5090) tensor([ 1.0000, -0.6154], grad_fn=<AsStridedBackward>) tensor([0., -0.], grad_fn=<MulBackward0>)\n",
      "u,l,Rho,k: tensor(0.5090) tensor(0.4877) tensor([ 1.0000, -0.6154], grad_fn=<AsStridedBackward>) tensor([ 1.0000, -0.6154], grad_fn=<MulBackward0>)\n",
      "u,l,Rho,k: tensor(-0.) tensor(-0.) tensor([0., 0.], grad_fn=<AsStridedBackward>) tensor([0., 0.], grad_fn=<MulBackward0>)\n",
      "kappa: tensor([[ 0.0000,  0.0000],\n",
      "        [ 1.0000, -0.6154],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000]], grad_fn=<TBackward>)\n",
      "bar_I: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "bar_lower_bds[pos_bar_L]: tensor([[-0.0000],\n",
      "        [ 0.4877],\n",
      "        [-0.5090],\n",
      "        [-0.5090],\n",
      "        [-0.0922],\n",
      "        [-0.5090],\n",
      "        [-0.5090],\n",
      "        [-0.3550]])\n",
      "upper_max_term: tensor([0., 0.], grad_fn=<SumBackward2>)\n",
      "lower_max_term: tensor([0., 0.], grad_fn=<SumBackward2>)\n",
      "\n",
      "\n",
      "2 ReLU()\n",
      "kappa: tensor([[ 0.0000,  0.0000],\n",
      "        [ 1.0000, -0.6154],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000]], grad_fn=<TBackward>)\n",
      "d: tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "nu: tensor([[ 0.0000,  0.0000],\n",
      "        [ 1.0000, -0.6154],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000]], grad_fn=<MulBackward0>)\n",
      "I: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "upper_relu_term: tensor([0., 0.], grad_fn=<SumBackward2>)\n",
      "lower_relu_term: tensor([0., 0.], grad_fn=<SumBackward2>)\n",
      "\n",
      "\n",
      "3 Linear(in_features=5, out_features=8, bias=True)\n",
      "\n",
      "\n",
      "nu_x: tensor([[ 0.3598, -0.8551, -1.3404, -0.8318, -0.5547]])\n",
      "upper: tensor([[ 1.0486, -0.7057]], grad_fn=<SubBackward0>)\n",
      "lower: tensor([[ 1.0273, -0.7188]], grad_fn=<AddBackward0>)\n",
      "u: tensor([[ 1.0486, -0.7057]], grad_fn=<SubBackward0>)\n",
      "l: tensor([[ 1.0273, -0.7188]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = []\n",
    "upper_bds = []\n",
    "lower_bds = []\n",
    "bar_upper_bds = []\n",
    "bar_lower_bds = []\n",
    "D = []\n",
    "out = []\n",
    "\n",
    "uR_bds = []\n",
    "lR_bds = []\n",
    "\n",
    "input = x\n",
    "\n",
    "for idx,layer in enumerate(model):\n",
    "    \n",
    "    print('\\n')\n",
    "    net.append(layer)\n",
    "    print(idx,layer)\n",
    "    \n",
    "    if isinstance(layer, nn.Linear):\n",
    "        \n",
    "        if idx == 0:\n",
    "            u,l = get_upper_lower(x,epsilon,net)\n",
    "            \n",
    "        else:\n",
    "            u,l = get_upper_lower(x, epsilon, net, D, upper_bds, lower_bds, bar_upper_bds, bar_lower_bds)\n",
    "        \n",
    "        upper_bds.append(u)\n",
    "        lower_bds.append(l)\n",
    "    \n",
    "        print('u:',upper_bds[-1])\n",
    "        print('l:',lower_bds[-1])\n",
    "    \n",
    "    if isinstance(layer, nn.ReLU):\n",
    "        z = out[-1]\n",
    "        print('z:',z)\n",
    "        D_, D_u, D_b, D_l = get_matrix_d(l,u,z)\n",
    "        D.append(D_)\n",
    "        #print(\"D:\",D)\n",
    "        #print(\"D_u:\",D_u)\n",
    "        #print(\"D_b:\",D_b)\n",
    "        #print(\"D_l:\",D_l)\n",
    "        \n",
    "#         print('\\n')\n",
    "        print('triangle')\n",
    "        u_, l_ = get_middle_u_l_(D_u, D_b, D_l, z, u)\n",
    "        \n",
    "        print(\"u_:\",u_)\n",
    "        print(\"l_:\",l_)\n",
    "        \n",
    "        #print('\\n')\n",
    "        u__, l__ = optimize_ReLU_bound(x, net, D[-1] , upper_bds, lower_bds)\n",
    "        print('optimization')\n",
    "        print(\"u__:\",u__)\n",
    "        print(\"l__:\",l__)\n",
    "        \n",
    "        uR_bds.append(u_)\n",
    "        lR_bds.append(l_)\n",
    "    \n",
    "    if isinstance(layer, nn.MaxPool1d):\n",
    "        zR = out[-1]\n",
    "        print(\"zR:\",zR)\n",
    "        \n",
    "        zM = get_ZM(zR)\n",
    "        print('zM:',zM )\n",
    "        \n",
    "        bar_u, bar_l = get_bar_u_l(uR_bds[-1], lR_bds[-1], zM, zR)\n",
    "        print('bar_u:',bar_u)\n",
    "        print('bar_l:',bar_l)\n",
    "        \n",
    "        bar_upper_bds.append(bar_u)\n",
    "        bar_lower_bds.append(bar_l)\n",
    "    \n",
    "    out.append(layer(input))\n",
    "    input = out[-1]\n",
    "    \n",
    "    if idx == 3 : break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check corectness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check last layer\n",
    "\n",
    "def check_corectness(test_num, epsilon, X, net, upper, lower):\n",
    "    \n",
    "    random = []\n",
    "    for i in range(test_num):\n",
    "        \n",
    "        #-------------- linear\n",
    "        a = np.random.uniform(-epsilon,epsilon,(X.size(1),X.size(2)))\n",
    "        random.append(a)\n",
    "\n",
    "    random = torch.from_numpy(np.array(random)).float()\n",
    "    \n",
    "    # -------------- linear\n",
    "    \n",
    "\n",
    "    test_x = random + X\n",
    "    \n",
    "    print('test_x size:',test_x.size())\n",
    "    out = net(Variable(test_x))\n",
    "    out = out.view(test_num,torch.numel(out[0]))\n",
    "    #print(out)\n",
    "\n",
    "    a = out < upper\n",
    "    b = out > lower\n",
    "    \n",
    "    check = torch.sum(a*b)\n",
    "    correct_num = torch.numel(out)\n",
    "    \n",
    "    if check == correct_num :\n",
    "        print(\"Correct ! \")\n",
    "    else :\n",
    "        print(\"False!\")\n",
    "    \n",
    "    #return 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar_u: tensor([[0.0102, -0.0000, 0.0319, -0.0000]])\n",
    "#bar_l: tensor([[-0.0887, -0.0102, -0.0754, -0.0524]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test maxpool  / ReLU  upper lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[ 0.5936,  0.1318, -0.2214,  1.0526, -1.6974]]])\n"
     ]
    }
   ],
   "source": [
    "uM =  torch.tensor([0.0000, 0.0000, 0.0000, 0.6204, 0.9708])\n",
    "lM =  torch.tensor([0.0000, 0.0000, 0.0000, 0.4812, 0.5358])\n",
    "\n",
    "# bar_u, bar_l\n",
    "u_=  torch.tensor([0.0102, -0.0000, 0.0319, -0.0000])\n",
    "l_=  torch.tensor([-0.0887, -0.0102, -0.0754, -0.0524])\n",
    "\n",
    "print('x:',x)\n",
    "random = []\n",
    "for i in range(10000):\n",
    "\n",
    "    #-------------- linear\n",
    "    a = np.random.uniform(-epsilon,epsilon,(x.size(1),x.size(2)))\n",
    "    random.append(a)\n",
    "\n",
    "random = torch.from_numpy(np.array(random)).float()\n",
    "\n",
    "# -------------- linear\n",
    "\n",
    "\n",
    "test_x = random + x\n",
    "\n",
    "test_y = model[:2](test_x)\n",
    "#for linear\n",
    "# a = test_y <= u\n",
    "# b = test_y >= l\n",
    "# print((a*b).sum() == 4*10000)\n",
    "\n",
    "\n",
    "#for maxpool\n",
    "# a = test_y <= uM[4]\n",
    "# b = test_y >= lM[4]\n",
    "# print(\"max value:\",torch.max(test_y).data)\n",
    "# print(\"min value:\",torch.min(test_y).data)\n",
    "\n",
    "# # for relu\n",
    "#test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 8])"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 4-dim zR check\n",
    "# zM = torch.zeros(10000,1,1)\n",
    "# result_1 = torch.max(zM[:,:,0], test_y[:,:,0])\n",
    "\n",
    "# result_2 = torch.max(result_1, test_y[:,:,1])\n",
    "# result_3 = torch.max(result_2, test_y[:,:,2])\n",
    "# result_4 = torch.max(result_3, test_y[:,:,3])\n",
    "# zM = torch.cat((zM[:,:,0], result_1, result_2 , result_3),1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zR = test_y\n",
    "# z_bar = zR-zM\n",
    "# a = (z_bar[0] <= u_)\n",
    "# b = (z_bar >= l_)\n",
    "# (a*b).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test RELU upper lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final term\n",
      "u: tensor([[ 1.1179, -0.5680]], grad_fn=<SubBackward0>)\n",
      "l: tensor([[ 1.0932, -0.5832]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Final term')\n",
    "print('u:',upper_bds[-1])\n",
    "print('l:',lower_bds[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_x size: torch.Size([100000, 1, 5])\n",
      "Correct ! \n"
     ]
    }
   ],
   "source": [
    "out = check_corectness(test_num = 100000, epsilon = 0.01, X = x, net = model, upper = upper_bds[-1], lower = lower_bds[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import matplotlib.patches as patches\n",
    "from scipy.spatial import HalfspaceIntersection\n",
    "\n",
    "%matplotlib inline\n",
    "seaborn.set(font_scale=2)\n",
    "seaborn.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lower bound : tensor into numpy\n",
    "zl = lower_bds[-1].squeeze(0).data.numpy()\n",
    "zu = upper_bds[-1].squeeze(0).data.numpy()\n",
    "out = out.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.Rectangle at 0x15f0f5f9208>"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot the out points (red points)\n",
    "# wheather it is over the upper/lower bound points (blue points)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(out[:,0],out[:,1],s=30,c='orange',marker='o',alpha=0.5,label='C1')\n",
    "ax.scatter(zl[0],zl[1],s=60,c='blue',marker='o',alpha=0.5,label='C1')\n",
    "ax.scatter(zu[0],zu[1],s=60,c='blue',marker='o',alpha=0.5,label='C1')\n",
    "\n",
    "ax.text(zl[0]-0.003, zl[1]-0.003, \"[%.4f , %.4f]\"%(zl[0],zl[1]), ha=\"center\", va=\"center\", size=10)\n",
    "ax.text(zu[0]+0.003, zu[1]+0.003, \"[%.4f , %.4f]\"%(zu[0],zu[1]), ha=\"center\", va=\"center\", size=10)\n",
    "\n",
    "ax.add_patch(patches.Rectangle((zl[0], zl[1]), zu[0]-zl[0], zu[1]-zl[1], fill=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9887],\n",
       "        [-0.0486]], requires_grad=True)"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model[3].weight\n",
    "b = model[3].bias\n",
    "w\n",
    "\n",
    "zM_u = 0.9708\n",
    "zM_l = 0.5358\n",
    "\n",
    "u1 = (w[0][0]*zM_l + b[0]).data.numpy()\n",
    "u2 = (w[1][0]*zM_u + b[1]).data.numpy()\n",
    "\n",
    "l1 = (w[0][0]*zM_u + b[0]).data.numpy()\n",
    "l1 = (w[1][0]*zM_l + b[1]).data.numpy()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.Rectangle at 0x15f0cfc2dd8>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAE4CAYAAABlvCnWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XtcVVX+//HXAUFRQNAMgzJMQ00liyYaL413Cq28NAIalrcaA21ETTNzSqe0LBVQS3t8veQVLS9N+rVMTZvRfonYxTL5pqZigSAhIMrt7N8fDKfIgxxE3QLv5z8Na+2192fvM75ZrLP3ORbDMAxEROS6czK7ABGR2koBLCJiEgWwiIhJFMAiIiZRAIuImKSO2QU44uLFixw6dIgmTZrg7OxsdjkiUkMUFxeTnp5Ou3btqFev3nU/frUI4EOHDjFkyBCzyxCRGmrVqlXcd9991/241SKAmzRpApRcpKZNm5pcjYjUFKmpqQwZMsSWMddbtQjg0mWHpk2bcuutt5pcjYjUNGYtbepNOBERkyiARURMogAWETGJAlhExCQKYBERkyiARURMogAWETGJAlhExCTV4kGMUhEREQwfPpxhw4aVaZ8/fz6fffYZderUYcqUKQQGBpbpX7p0Ke+//z6NGjUC4JVXXsHX15eJEydy9uxZGjRowOuvv05xcTExMTG2cYcPH2b8+PH07duXiRMnkpubS2FhIZMnT+aee+6psN7MzEwmTJjAxYsXufnmm5k5cyZubm62/tJ9nT59GicnJ2bMmEGLFi04fPgw//jHP3B2dsbf359XX30VJycn1q1bx9q1a6lTpw6jR4+mW7dupKenM2HCBAoLC2nSpAmzZs1i9+7dzJs3j549ezJhwoSqXHIRuZaMauDUqVNGQECAMW3atEv6Dh06ZERGRhpWq9U4ffq0MWDAgEu2GT9+vPHtt9+WaVuyZIkRFxdnGIZhfPTRR8aMGTPK9CclJRmRkZFGUVGRERsbayxdutQwDMM4evSo0a9fP4fqnjFjhvHBBx8YhmEYixYtsu2j1Pbt242xY8cahmEY//73v43o6GjDMAzj2WefNT777DPDMAwjJibG2LFjh3HmzBmjb9++Rn5+vpGdnW373//85z+NjRs3GoZhGHFxcbZjfPDBB8bs2bMdqlOktirNllOnTply/Gq/BHHgwAE6d+6MxWLB19eX4uJiMjMzSzrPn4LVFr7b9z6Lp/YmIiKCRYsW2cZ16dIFgAcffJB9+/bZ9mkYBjNmzODll1/G2dmZp556ivDwcKDk05Pq1q1LQQF8/jl8+GHJfwsK7Nf2+2Ps3bu3TH/z5s0pLi7GarWSm5tLnTolf5C0adOGrKwsDMPg/Pnz1KlTh2+++YZ77rkHV1dXPDw8aNasGT/88ANTpkzh0UcfxWq18ssvv9C4ceOren1F5NqpVksQ9uTm5uLl5WX7uUGDBuTk5NAodxf8+3EA+rTNYfD9WbjXXUv05x7s2rWL3NxcPDw8yowptXPnTu68807uuOMOADw9PQFIT09n4sSJREZO4fXXobAQnJzAaoXPPoOwMAgIKFtbeccAqF+/PqdPn+bhhx/m119/5Z133gHA39+f6dOn8/bbb+Ph4UFwcDDbtm2z7at0f7m5uVgsFoqKinjsscfIz88nKirqKl1ZEbnWquUM+JlnniEyMpIZM2bg7u7O+fPnbX3nz5/HwznbFr6GAU8+kEWj+lZcneEvDdbx/ffflxl3/vx5W8gCfPjhhwwaNKjMMY8cOcJTTz3FmDHj+P77+ykuLglfKPlvcTEkJJSdCV/uGADLli2jc+fOfPzxx2zevJnJkyeTn5/Pq6++yqpVq9i2bRv9+vVj1qxZ9s/zv4Hs4uLC1q1bmTFjBpMmTari1RWR66VazoBLlxGg5LOCZ8+ezYgRI0hNTcVqtdKozllbf26+E33fvp2tUT9R38Xg/x2vz0CvSbjdG8fu3bsJDAxkz549BAUF2cZ899133Hvvvbaff/zxR5577jnmzZtHenrr3818i/n116O27axWeP99KP1Y0TvuuIOEhAR69uzJBx98wO23305ycrJt+8LCQqxWK8nJyVy8eJELFy5w5MgR3NzcOHPmDIZhUFRUREpKCu7u7uzdu5dDhw5RWFjI4cOHsVgs/P3vf6dz584EBgZy9uxZLl68SHJyMqmpqWRmZpY5nkhN16JFi2r1pQ3VMoB/r127dtx3332EhYVhtVqZNm0aePjwr289yCtwIizoHOO6ZzB0+W24Ohv8uXkef7nzPPf3j2DSpElERETg4uLCW2+9BZTcudCgQQMsFovtGG+99RYFBQW8+uqrZGRAfr47Dz74Nr/+epRffz2Ot3dzvvnmDVq1GsW5c962cYMGDWLevHl88skneHp62u5ImDNnDk888QSPPfYYsbGxTJo0iaKiIiIjI6lXrx5jxoxh9uzZODk54eLiQnR0NN7e3jzyyCNMmjQJwzCIjIzE1dWVRx55hIULF7J27VosFgujR4++vi+AyA3i+PHjAAT8fh3wBmcxDMMwu4iKpKSk0KNHD8LDw3nllVccG7TaUvE2gyt/6p9/Dtu3l8yAz54tmV02bhzA11/PoU2bv/Hww/X57/tuptqwYQPHjh3TbWhSa5T+tVeZAC7Nlh07dpjyWePVag14586dLF261LGNHQlXR0L6D4KDwcXl0vaWLcNxc6vPAw9UepdX3bZt21i8eLHZZYhIBarVEsSaNWsq91uq1xewvYJEXG2p1EzY1bXkboeEhJI139K7IDw9fQkLsx/O19tDDz3EQw89ZHYZIlKBahXAldYk2LHtKhnCAQEwaVLJG27nzkG7dvDAAzdG+IpI9VGzAxhKgvUKlhoq4ur6290O1WjNX0RuINVqDfiKXaP1YBGRqqgdAQwKYRG54dSeAHaUQlhErpPaFcBXcN+viMi1UrsCGLQUISI3jNoXwKAQFpEbQu0MYEcphEXkGqq9Aaz1YBExWe0NYNBShIiYqnYHMCiERcQ0CmBHKYRF5CpTAIPj68EKYRG5ihTApfSmnIhcZwrg39N6sIhcRw4HcFFREcuWLSM0NJTAwEB69OjBggULKCwsdGj8Dz/8wOjRo/nTn/5E+/bteeSRR0hISLjiwq8ZhbCIXCcOB/D06dOZOXMmXl5eDB06FB8fH+Li4hg/fnyFY3/44QciIiLYvXs3Dz74IBEREeTl5TFt2jRmz55dpRMwjUJYRKrIoQ9kT0pKIiEhgZCQEGJjY7FYLBiGweTJk9m0aRO7du2iW7du5Y6fN28eeXl5LFiwgJ49ewLw3HPPMWDAAJYsWUJ4eDi33Xbb1Tmjq+EafYi7iMjvOTQDXrVqFQDR0dG2r2u3WCzExMRgsVhYv379Zcd/++23NGzY0Ba+AA0aNKBv375YrVa+/fbbK63/2nFkKeJfra59HSJSYzkUwImJiXh7e1/ydc8+Pj74+/uzf//+y4738vIiNzeXc+fOlWlPS0sDwNvbuzI1Xz8KYRG5hioM4IKCAlJTU2nWrJndfj8/P7Kzs8nMzCx3H+Hh4RQXFzN+/HhOnDhBbm4u77//Phs3bqRt27bcf//9V34GNwItV4jIFahwDTgrKwsADw8Pu/2l7Tk5OTRq1MjuNpGRkTg7O/Paa6/Ru3dvW3unTp2YM2cOzs7OlS78utF6sIhcIxXOgIuKigBwdXW121/anp+fX+4+vvrqKxYvXoyLiwv9+vUjMjKSFi1asHfvXmJjYzGMG/whCN2aJiLXQIUz4Hr16gGUe79vQUEBAG5ubnb7c3NzeeaZZ7BarWzYsIHmzZvbxk2YMIHVq1fTsmVLhgwZckUncN04MhNebdETdSLisApnwO7u7jg5OZGbm2u3PycnByh/iWLHjh1kZWURGRlpC18omTn/4x//AGDjxo2VLvyGteFOsysQkWqiwgB2dXXF19eXlJQUu/0pKSl4e3vj5eVltz81NRWAFi1aXNLXuHFjvL29+eWXXypTs3kcmd1e/PHa1yEiNYJDt6EFBQWRnp7O8ePHy7SnpaVx4sQJOnToUO7Yxo0bA1wyFuDcuXNkZWVx0003VaZmc1UYwnWvSxkiUv05FMD9+vUDYO7cuVitVgAMw2DOnDkYhkFYWFi5Y7t164abmxsrV67k1KlTtvbi4mJmzZqFYRj06dOnKudw/V0uhP+08PrVISLVmkOPInfs2JHQ0FC2bt1KWFgYwcHBHDx4kMTEREJCQujatatt2/j4eADGjBkDlMyAX3rpJaZOncpjjz1GSEgInp6efPHFF/zwww/cf//9PPXUU1f9xK65wQa89Yc35bzvgzuHm1OPiFQ7DgUwwBtvvEHLli3ZuHEjy5cvx9fXl7FjxzJq1Cjb48kA8+fPB34LYICBAwfi5+fHu+++y/bt27l48SK33XYbzz33HCNHjiz3Frcb3iNH4Kf3oW4i+PZV+IpIpTgcwC4uLkRFRREVFXXZ7Y4cOWK3/YEHHuCBBx6oXHXVgf/jEDDF7CpEpBrSB7KLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhIFsIiISRTAIiImUQCLiJhEASwiYhKHA7ioqIhly5YRGhpKYGAgPXr0YMGCBRQWFjo0Pj8/n/nz5xMSEkL79u3p2bMnr732GtnZ2VdcvIhIdeZwAE+fPp2ZM2fi5eXF0KFD8fHxIS4ujvHjx1c4trCwkJEjRxIfH8/NN99MZGQkt9xyC8uXL2fkyJEUFBRU6SRERKqjOo5slJSUREJCAiEhIcTGxmKxWDAMg8mTJ7Np0yZ27dpFt27dyh3/3nvv8eWXXzJixAief/55W/v06dNZtWoVW7dupV+/flU/GxGRasShGfCqVasAiI6OxmKxAGCxWIiJicFisbB+/foKx/v5+TFu3Lgy7cOHD6d///7UrVv3SmoXEanWHJoBJyYm4u3tTUBAQJl2Hx8f/P392b9/f7ljf/zxR06fPk1kZCQuLi5l+m699VZmzZp1BWWLiFR/Fc6ACwoKSE1NpVmzZnb7/fz8yM7OJjMz025/cnIyAHfeeSe7d+8mPDycu+++m86dOzNr1izy8vKqUL6ISPVVYQBnZWUB4OHhYbe/tD0nJ8du/5kzZwDYtWsXTz/9NJ6enoSHh9OkSROWLl3KyJEjHb6TQkSkJqlwCaKoqAgAV1dXu/2l7fn5+Xb7L1y4AJQE8IwZMxg0aBAAxcXFxMTEsG3bNlavXs2TTz5Z+epFRKqxCmfA9erVAyh3llp6C5mbm5v9AziVHOKuu+6yhS+As7Oz7Y6I//3f/61EySIiNUOFAezu7o6TkxO5ubl2+0uXHspbonB3dwdKAviP/Pz88PT05NSpUw4XLCJSU1QYwK6urvj6+pKSkmK3PyUlBW9vb7y8vOz2+/v7A+XPoIuKimyzbBGR2sSh+4CDgoJIT0/n+PHjZdrT0tI4ceIEHTp0KHdsYGAgrq6u7N+/n+Li4jJ9R48eJS8vj1atWl1B6SIi1ZtDAVz6lNrcuXOxWq0AGIbBnDlzMAyDsLCwcsd6eHjw8MMP8/PPP7N48WJbe2FhIbNnzwZg4MCBV3wCIiLVlUMPYnTs2JHQ0FC2bt1KWFgYwcHBHDx4kMTEREJCQujatatt2/j4eADGjBlja5s0aRJfffUV8+bN48svv6R169bs27ePw4cPExoaSo8ePa7uWYmIVAMOBTDAG2+8QcuWLdm4cSPLly/H19eXsWPHMmrUKNvjyQDz588HygZw48aNSUhIYMGCBWzfvp3ExET8/PyYOHEiw4YNu4qnIyJSfTgcwC4uLkRFRREVFXXZ7Y4cOWK33dvbm6lTpzJ16tTKVSgiUkPpA9lFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREyiABYRMYkCWETEJApgERGTKIBFREzicAAXFRWxbNkyQkNDCQwMpEePHixYsIDCwsJKH9RqtTJo0CBatWpV6bEiIjWFwwE8ffp0Zs6ciZeXF0OHDsXHx4e4uDjGjx9f6YMuW7aMr7/+utLjRERqkjqObJSUlERCQgIhISHExsZisVgwDIPJkyezadMmdu3aRbdu3Rw64MmTJ4mNja1S0SIiNYFDM+BVq1YBEB0djcViAcBisRATE4PFYmH9+vUOHcwwDF588UVuvvlm/P39r6xiEZEawqEATkxMxNvbm4CAgDLtPj4++Pv7s3//focOtmbNGr788kumT59OvXr1Kl+tiEgNUmEAFxQUkJqaSrNmzez2+/n5kZ2dTWZm5mX388svv/Dmm2/y+OOP8+c///nKqhURqUEqDOCsrCwAPDw87PaXtufk5Fx2P9OmTaN+/fpMmjSpsjWKiNRIFb4JV1RUBICrq6vd/tL2/Pz8cvexadMm9uzZQ1xcHJ6enldSp4hIjVPhDLh0rba8+30LCgoAcHNzs9ufkZHBzJkz6dWrFyEhIVdap4hIjVNhALu7u+Pk5ERubq7d/tKlh/KWKKZPn05xcTHTpk2rQpkiIjVPhUsQrq6u+Pr6kpKSYrc/JSUFb29vvLy87PZ//PHHAHTp0sVuf6tWrfDz82Pnzp2O1iwiUiM49CBGUFAQmzdv5vjx4zRv3tzWnpaWxokTJ+jatWu5Y6Ojo+22r127loyMDKKjo8udPYuI1GQOBXC/fv3YvHkzc+fOZd68eTg5OWEYBnPmzMEwDMLCwsodO2bMGLvtn376KRkZGeX2i4jUdA4FcMeOHQkNDWXr1q2EhYURHBzMwYMHSUxMJCQkpMwMOD4+Hig/eEVEpIRDAQzwxhtv0LJlSzZu3Mjy5cvx9fVl7NixjBo1yvZ4MsD8+fMBBbCISEUcDmAXFxeioqKIioq67HZHjhxxaH+bN2929NAiIjWSPpBdRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZMogEVETKIAFhExiQJYRMQkCmAREZM4HMBFRUUsW7aM0NBQAgMD6dGjBwsWLKCwsNCh8YcOHeLZZ58lODiYdu3a0bNnT958803y8vKuuHgRkerM4QCePn06M2fOxMvLi6FDh+Lj40NcXBzjx4+vcOwXX3xBeHg4e/bsoXPnzkRGRuLl5cW7777L0KFDyc/Pr9JJiIhUR3Uc2SgpKYmEhARCQkKIjY3FYrFgGAaTJ09m06ZN7Nq1i27dupU7/pVXXsEwDNasWUNgYCAAhmEwbdo01q1bx+rVqxk2bNjVOSMRkWrCoRnwqlWrAIiOjsZisQBgsViIiYnBYrGwfv36csf++OOPHDt2jB49etjCt3R8VFQUAHv27LniExARqa4cmgEnJibi7e1NQEBAmXYfHx/8/f3Zv39/uWPd3d2ZMGHCJWMBXF1dAbQOLCK1UoUBXFBQQGpqKnfffbfdfj8/P44fP05mZiaNGjW6pL9p06aMGjXK7tjt27cD0LJly8rULCJSI1S4BJGVlQWAh4eH3f7S9pycnEodOCMjg7i4OADCwsIqNVZEpCaoMICLioqA35YL/qi0vTJ3MuTk5PD000+TkZFBZGRkmbVhEZHaosIArlevHkC59/sWFBQA4Obm5tABMzMzefLJJ/nuu+/o1q0bkydPdrRWEZEapcI1YHd3d5ycnMjNzbXbX7r0UN4Sxe+dPHmSESNGcPLkSbp3705sbCx16jj0PqCISLkKCiAxEc6dg7Q0CA6Gcv5ov6FUOAN2dXXF19eXlJQUu/0pKSl4e3vj5eV12f0cPnyY8PBwTp48Sf/+/YmPjy93WUNEbmwbNmyga9euLF26lMzMTIYPH87gwYP5+9//zoULFy7ZNjIyksjISAYNGkT79u3Jzs7m3//+N/369SMiIoKFCxcCUFxczAsvvEB4eDhDhgzh5MmTAIwbN862j+7duzNu3Djb/pOT4fXX4T//ge+/h+3bS35OToadO3cycOBAwsLCWLduXbnns3DhQtasWWP7+X/+538YMGAAAwcOtN0sUOro0aMEBQWVWXYtLi5m7Nixtltq586dS6dOnSq8xdah+4CDgoJIT0/n+PHjZdrT0tI4ceIEHTp0uOz4EydOMHz4cM6ePcuwYcOYOXOmZr4i1Vzfvn0ZNmwYCxcupG/fvqxevZq77rqLhISEMtsNGDCAFStWsGLFCtq2bcvUqVNxd3dn6tSpxMfHs2bNGo4dO0ZiYiK7du0CYO3atYwdO5aZM2cCJYG2YsUK5s+fj4eHBy+88AJQMvNNSIDiYnD6b5o5OZX8vGZNIa+9NpMlS5awYsUKEhISSE9PL1Nb6U0Ge/futbVlZ2ezYsUK1q5dy5IlS3jttddsfbm5ubz++utlJo8nT57kiSee4Ntvv7W1jRs3ji5dulR4DR1KwX79+rF582bmzp3LvHnzcHJywjAM5syZg2EYl72LwWq1EhMTQ2ZmJkOHDq1xa75//KUkUhukpqaSmZlJcnIy//nPf+jVqxfJycncfvvtvPfee3Ts2PGSMf/3f//HN998Q0REBImJidStW5cLFy6QnJzMrbfeyscff8xf//pXhg4dSnJyMklJSbi4uJCcnGzbx6JFi+jVqxdZWVlkZWWRmAipqSWh++uvx/H2bm7b9uzZo3h6NqNhw4ZAyUQyMTGRhx9+2LZN6Wy9V69etjY3Nzd8fX25cOECFy5csD18ZhgGL730EjExMTz77LO27fPy8vjnP//Ju+++W+nr6FAAd+zYkdDQULZu3UpYWBjBwcEcPHiQxMREQkJC6Nq1q23b+Ph4AMaMGQPAp59+yqFDh3B1daV+/fq2/t+76aabiIiIqHTxZmvRooXZJYiY7sKFC9SvXx8oCa/z58/b3W79+vW2f+cNGzYkPz+fU6dO4evrS2JiInfccQcAzs7OzJ07l3379pWZsGVlZfH1118zcuRIW9u5c7/NfL29m+Pt/du/yeLiXOrU+e29qQYNGlzyXtYtt9xit9ZbbrmFPn36UFxczDPPPAPA/Pnz+ctf/kLr1q3LbPvHnyvD4XWAN954g5YtW7Jx40aWL1+Or68vY8eOZdSoUbbfEKVFwm8BXPqUXEFBAe+8847dfbdu3bpaBrCzs7PdJ/xEarpDhw6Rl5dHQEAA3t7e+Pr60rhxY6xWKz4+Ppf8u8jOzubMmTM8/vjjtrZ58+bx1ltv4enpSfv27WnatKlt3Ntvv016ejqDBg1iy5Yt1K9fn1WrVjFw4EDatGlj20daGvzyy28h/HvOzu4UF//2y+D8+fMO3SywZ88ezpw5w44dOwAYMWIE9957Lx9++CFNmzblgw8+ID09neHDh9s+puFKORzALi4uREVF2T6/oTxHjhwp8/OLL77Iiy++eGXVicgN795772X37t0MGDCAPXv2EBQUdMk2+/fvv2RZYs+ePSxatAg3Nzeio6MZMGAAmzZtIi0tjWeeeQY3NzcsFgvOzs4A7Nu3j9GjR5fZR3AwfPZZyZrvHzVu3ILDh0+QlZVF/fr1SUxMZMSIERWeT8OGDalXrx6urq5YLBY8PDzIzs4u82Zc9+7dWbJkiQNX5/L0gewiUiWjR49my5YthIeHc/DgQZ544gkAnn/+eX7++Weg5L2SW2+9tcy4pk2bEhERQXh4OH/+85+588476d27N99//z1DhgxhxIgRTJkyhbp169r2cdttt5XZh6srhIXBuXOHSUx8FQCrFZydISLChRdemMyIESMIDw9n4MCB+Pj48OOPP/Lyyy+Xez733Xcf7du3Z9CgQYSFheHv70+nTp2u1uUqw2IYhnFN9nwVpaSk0KNHD3bs2HHJiygi19+GDRs4duwYEyZMMLsUALKy8njllXfo1i0Gb2944AFwcal43LXMlsmTJxMaGsqDDz5Y7jaaAYvIFfnoo49YunSp2WUA4OxczIwZT/Poo9Cli2Phey3NnTuXzz//vMLtNAMWkVrL7GzRDFhExCQKYBERkyiARURMogAWETGJAlhExCTV4iPJiv/7mEtqaqrJlYhITVKaKcX2HqW7DqpFAJd+hNyQIUNMrkREaqL09HRuv/32637canEf8MWLFzl06BBNmjSxPRcuIlJVxcXFpKen065dO9vXr11P1SKARURqIr0JJyJiEgWwiIhJFMAiIiZRAIuImKRa3IZ2o/jll1+YM2cOX3zxBbm5ubRp04bo6Gi7X0Boz4kTJ+jdu3e5/d98843tw6druqKiIlauXMm6detISUmhSZPjji0OAAAHh0lEQVQmDBgwgKeffhoXBz5LMCsri7i4OD777DPOnj1LixYtGDlyJKGhodeh+htbVa9tREQESUlJdvtefvnlavn1YTcqBbCDMjIyGDx4MOnp6TzyyCN4eHiwZcsWhg8fzoIFC+jRo0eF+yj9uqbQ0FDbFxD+Xm26xW769OkkJCQQFBRE9+7dSUpKIi4ujiNHjhAXF3fZsXl5eQwfPpzvv/+ehx9+mFtuuYVPPvmEcePGkZmZaftGhtqqKtcWSr69uHnz5vTp0+eSvnbt2l2LkmsvQxwydepUIyAgwNi5c6etLTU11ejUqZPRpUsXIz8/v8J9xMXFGQEBAcbhw4evZak3vAMHDhgBAQHGmDFjDKvVahiGYVitVuP555+/5Brb8/bbbxsBAQHGypUrbW05OTlGnz59jLvvvtvIyMi4pvXfyKp6bU+dOmUEBAQYr7322vUot9bTGrADzp8/z6ZNm2jbti3dunWztfv4+BAZGUlaWhp79uypcD9HjhzBxcWl1n+dfek3yUZHR9u+UdtisRATE4PFYmH9+vWXHb969WpuuukmwsPDbW3u7u787W9/48KFC/zrX/+6dsXf4Kp6bUv/SmvVqtW1LVQAvQnnkG+++YaCggKCg4Mv6Stt+/LLLyvcz5EjR2jevLlD63A1WWJiIt7e3pd8dbmPjw/+/v7s37+/3LEnT54kLS2NoKCgS5ZsSl+Ly42v6apybUEBfL0pgB1w8uRJAJo1a3ZJn5+fHwA//fTTZfeRl5fHqVOnaNSoEa+88grdu3cnMDCQ/v378+GHH171mm9UBQUFpKam2r2WUHI9s7OzyczMtNt/udeiSZMm1K1bt8LXoqaq6rWFkgC2WCwkJSXRv39/OnTowIMPPsirr75KTk7OtSq91lIAOyArKwsAT0/PS/o8PDwAKvw/Z3JyMoZh8MUXX3DgwAFCQkIIDQ3l9OnTTJw40aE3R2qC0mtZet3+qKLrebnXAkqWImprUFT12kJJABuGQWxsLHfddRd//etfadSoEe+99x6DBw8mNzf36hdei9XquyC6d+/O6dOnL7vNkCFDaNSoEQCurq6X9Je25efnX3Y/OTk5NG/enE6dOvHiiy/i5FTyuy8tLY2IiAgWLlxI7969ad269ZWcSrVRVFQE2L+Wv28v73o6Mv7ChQtVLbNaquq1tVqteHp60qZNGxYtWoSPj4+t/eWXXyYhIYH4+HheeOGFa1B97VSrA7hnz56X/XMMIDAwkIyMDAAKCwsv6S8oKACgfv36l91Ply5d2LZt2yXtPj4+REVFMWXKFLZs2VLjA7j0E6fsXUv47Xq6ubnZ7S+9T7p0O3vjK3otaqqqXlsnJyfWrVtnt33SpEl8+OGHbNmyRQF8FdXqAJ4yZYpD25W+c2zvT7fSNnd39yuuo23btkDJV2TXdO7u7jg5OZX7p2zp9Szvz+iGDRsClDs+NzeXxo0bX4VKq5+qXtvLadCgAf7+/hw+fJiLFy+a8tGNNZHWgB3g7+8P2A/I0rbmzZtfdh8nT55k3759dv88vnjxIkCteArO1dUVX1/fcn/ZpKSk4O3tjZeXl93+y70WZ86cIT8/v8LXoqaq6rXNzs4mKSmJ48eP2+2/ePEiTk5Otf4unqtJAeyAtm3bUq9ePbu38JTefnbPPfdcdh/z58/nqaee4vPPP7+k78CBA0DtecooKCiI9PT0S/6hp6WlceLECTp06FDuWF9fX3x9fTlw4ABWq7VMn6OvRU1WlWv73XffERERweuvv35J35kzZ0hJSaFNmza16onNa00B7ID69evTq1cvDh48yI4dO2ztaWlprFixgptvvpmuXbtedh8PPfQQAAsWLCAvL8/WfuzYMRYvXkzDhg3p27fvNan/RtOvXz8A5s6dawtRwzCYM2cOhmEQFhZ22fGPPvooqamprFy50taWm5vLO++8Q7169XjssceuXfE3uKpc26CgIJo0acKePXvK3NdeUFDAjBkzKCws1NeCXWX6RgwH/fzzzwwcOJDs7Gz69OmDt7c3W7Zs4ezZs8THx9OzZ0/btocPH+bTTz+lTZs2ZdrHjx/PRx99hJ+fH927dyc7O5vt27dTUFBAfHw83bt3N+PUTDFu3Di2bt1KYGAgwcHBHDx4kMTEREJCQoiNjbU9xRUfHw/AmDFjbGNzc3MZOHAgP/30E7179+a2227jk08+4dSpU7z00ku1/rMgqnJtd+3aZXuK7qGHHsLLy4u9e/dy9OhR+vTpw1tvvWUbL1WnAK6EkydP8uabb7Jv3z6Ki4tp3bo1UVFRdOrUqcx2GzZs4IUXXqB///7MmjXL1m61Wlm5ciXr16/n+PHjuLm5ce+99xIVFUVgYOD1Ph1TFRYWsnjxYjZu3EhaWhq+vr48+uijjBo1qsxtVKVPZJU+oVUqIyODOXPmsGvXLi5cuMAdd9zBiBEj7H6ATG1T1Wv71VdfsXDhQpKSkmxr6oMGDWLw4MG22yfl6lAAi4iYRL/ORERMogAWETGJAlhExCQKYBERkyiARURMogAWETGJAlhExCQKYBERkyiARURMogAWETHJ/wfR3iZlO/fzmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot the out points (red points)\n",
    "# wheather it is over the upper/lower bound points (blue points)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(out[:,0],out[:,1],s=30,c='orange',marker='o',alpha=0.5,label='C1')\n",
    "\n",
    "ax.scatter(l1,l2,s=60,c='blue',marker='o',alpha=0.5,label='C1')\n",
    "ax.scatter(u1,u2,s=60,c='blue',marker='o',alpha=0.5,label='C1')\n",
    "\n",
    "ax.text(l1-0.003, l2-0.003, \"[%.4f , %.4f]\"%(l1,l2), ha=\"center\", va=\"center\", size=10)\n",
    "ax.text(u1+0.003, u2+0.003, \"[%.4f , %.4f]\"%(u1,u2), ha=\"center\", va=\"center\", size=10)\n",
    "\n",
    "ax.add_patch(patches.Rectangle((l1, l2), u1-l1, u2-l2, fill=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4878, 1.1139, 0.6698]]])"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.load('maxpool_x_.pt')\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
